# base
caption_model: augv3
input_json: ../retina_wp/retina3_talk.json
input_att_dir: ../retina_wp/retina1_att
input_fc_dir: ../retina_wp/retina1_fc
input_label_h5: ../retina_wp/retina3_label.h5

learning_rate: 0.0005
scheduled_sampling_start: 0
checkpoint_path: logs/r3_augv3
# $start_from
language_eval: 1
#save_checkpoint_every: 3000
save_every_epoch: True
save_history_ckpt: True
val_images_use: -1

train_sample_n: 5
self_critical_after: -1
batch_size: 10
learning_rate_decay_start: 0
max_epochs: 30
max_length: 60

# Notice: because I'm to lazy, I reuse the option name for RNNs to set the hyperparameters for transformer:
# N=num_layers
# d_model=input_encoding_size
# d_ff=rnn_size

num_layers: 6
input_encoding_size: 512
rnn_size: 2048

# Transformer config
N_enc: 6
N_dec: 6
d_model: 512
d_ff: 2048
num_att_heads: 8
dropout: 0.1

#r2 config
rm_num_slots: 6
rm_num_head: 16
rm_d_model: 512

REFORWARD: false